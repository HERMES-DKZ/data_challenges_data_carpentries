{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aebfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy import geocoders\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de810239",
   "metadata": {},
   "source": [
    "### Doing some entitiy recognition on the first article of the first newspaper in the first df, using spacy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8231adb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# ! python -m spacy download de_core_news_sm\n",
    "\n",
    "# nlp = spacy.load(\"de_core_news_sm\")\n",
    "# doc = nlp(df.iloc[0,13])\n",
    "\n",
    "# for ent in doc.ents: \n",
    "#     \"\"\"\n",
    "#     Getting the names of all locations within the loaded newspaper article:\n",
    "#     \"\"\"\n",
    "#     if ent.label_== 'LOC':\n",
    "#         print(ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0e1d6",
   "metadata": {},
   "source": [
    "Let's see whether \"Widdig\" from the above list is really a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9479412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wikipedia as wiki\n",
    "# wiki.set_lang(\"de\")\n",
    "\n",
    "# search_string = 'Widdig'\n",
    "# page = wiki.page(search_string)\n",
    "# content = page.content\n",
    "# content[0:680]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5621065",
   "metadata": {},
   "source": [
    "### loading pickled dataframes, making new dataframes out of them and saving them to the local drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d90985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pickled_df_loader (year, columns):\n",
    "#     \"\"\"\n",
    "#     loads dataframes from the pickled dfs. \n",
    "#     \"\"\"\n",
    "#     df= pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/newspapers_ger_{year}_part_1\")[columns]\n",
    "#     df= pd.concat ([df, pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/newspapers_ger_{year}_part_2\")[columns]]\\\n",
    "#                    , axis=0)\n",
    "#     df= pd.concat ([df, pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/newspapers_ger_{year}_part_3\")[columns]]\\\n",
    "#                    , axis=0)\n",
    "    \n",
    "#     df['publication_date']= df['publication_date'].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "#     df['publication_date'] = pd.to_datetime(df['publication_date'], format='%Y-%m-%d')\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a91b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def challenge_df_generator (begin, end):\n",
    "#     \"\"\"\n",
    "#     loads all pickled dataframes belonging to the years in the year range and returns their concatenation as a single df. \n",
    "#     \"\"\" \n",
    "    \n",
    "#     columns= ['paper_title', 'publication_date', 'place_of_distribution']\n",
    "    \n",
    "#     df= pickled_df_loader (begin, columns)\n",
    "    \n",
    "#     for year in range (begin+1, end+1):\n",
    "#         df= pd.concat([df, pickled_df_loader(year, columns)], axis=0)\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b50fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newspapers_1914_1945_df = challenge_df_generator (1914, 1945)\n",
    "# newspapers_1914_1945_df.to_pickle(\"./data_deutsches_zeitungsportal_1914_1945/newspapers_no_article_1914_1945\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe922d6c",
   "metadata": {},
   "source": [
    "### Analyzing the dataframe containing all the data between 1914 and 1945:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4c4a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers_1914_1945_df= pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/newspapers_no_article_14_45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e3fb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#newspapers_1914_1945_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b06ca92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#newspapers_1914_1945_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a636124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newspapers_1914_1945_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b85348",
   "metadata": {},
   "source": [
    "#### Let's see what we can do with the lists of the cities: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e8e7",
   "metadata": {},
   "source": [
    "Extracting all places of distribution and storing them in a pickled python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352e0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_cities=[]\n",
    "# for city in newspapers_1914_1945_df['place_of_distribution']:\n",
    "#     if city not in unique_cities: \n",
    "#         unique_cities.append(city)\n",
    "        \n",
    "# import pickle\n",
    "# with open(f\"./data_deutsches_zeitungsportal_1914_1945/unique_cities.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(unique_cities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84dc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_list= pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/unique_cities.pkl\")\n",
    "# city_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa8690",
   "metadata": {},
   "source": [
    "Extracting names of single cities from the pickled city list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9722b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single_city_list= []\n",
    "\n",
    "# for place in city_list:\n",
    "#     if isinstance (place, list):\n",
    "#         for i in range(0, len(place)):\n",
    "#             if place[i] not in single_city_list:\n",
    "#                 single_city_list.append(place[i])\n",
    "#     else: \n",
    "#         if place not in city_list:\n",
    "#             city_list.append(place)\n",
    "\n",
    "# import pickle\n",
    "# with open(f\"./data_deutsches_zeitungsportal_1914_1945/single_cities.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(single_city_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8210913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities_1914_1945= pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/single_cities.pkl\")\n",
    "# cities_1914_1945"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300f1c8",
   "metadata": {},
   "source": [
    "Pinning the cities from a city list on the world map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88ae075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_maker(city_list):\n",
    "# #plots the cities in the city list on a map.\n",
    "    \n",
    "#     city_dict= {}\n",
    "#     gn= geocoders.GeoNames(username=\"golisf\")\n",
    "    \n",
    "#     for city in city_list:\n",
    "#         if not pd.isna(city):\n",
    "#             city_dict[city]= gn.geocode(city)\n",
    "            \n",
    "#     # Create a map centered at a location, you can adjust the coordinates and zoom level as needed\n",
    "#     map_center= [51.1657, 10.4515]  # Germany's approximate center\n",
    "#     my_map= folium.Map(location=map_center, zoom_start=6)\n",
    " \n",
    "#     # Add markers for each city\n",
    "#     for city in list(city_dict.keys()):\n",
    "#         folium.Marker(location=city_dict[city], popup=city).add_to(my_map)\n",
    "        \n",
    "#     return my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0357122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities_1914_1945= pd.read_pickle(f\"./data_deutsches_zeitungsportal_1914_1945/single_cities.pkl\")\n",
    "# map_maker(cities_1914_1945)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea123aa",
   "metadata": {},
   "source": [
    "#### Let's see what we can do with the paper titles: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c825bc8",
   "metadata": {},
   "source": [
    "Extracting the titles of available newspapers and storing them in a pickled python list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b429bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_papers=[]\n",
    "# for paper in newspapers_1914_1945_df['paper_title']:\n",
    "#     if paper not in unique_papers: \n",
    "#         unique_papers.append(paper)\n",
    "        \n",
    "# import pickle\n",
    "# with open(f\"./data_deutsches_zeitungsportal_1914_1945/unique_papers.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(unique_papers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38498da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_papers= pd.read_pickle(\"./data_deutsches_zeitungsportal_1914_1945/unique_papers.pkl\")\n",
    "# all_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89289b6",
   "metadata": {},
   "source": [
    "Create a df with the following columns: \n",
    "\n",
    "- name of newspaper\n",
    "- cities of distribution\n",
    "- date begin\n",
    "- date end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaa6b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_publication_df = newspapers_1914_1945_df.groupby('paper_title').agg(\n",
    "#     publication_begin=('publication_date', 'min'),\n",
    "#     publication_end=('publication_date', 'max'),\n",
    "#     place_of_distribution=('place_of_distribution', 'first')\n",
    "# ).reset_index()\n",
    "\n",
    "# paper_publication_df.to_pickle(\"./data_deutsches_zeitungsportal_1914_1945/paper_publication_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f52689",
   "metadata": {},
   "source": [
    "Running the above code, I realized that the same newspaper sometimes appears multiple times in the title, each time with minor changes (eg. issues and numbers are added to the title). So I optimized the code as below. In the below code, the newspaper title is tokenized and the the first three tokens of the title are added to the df as a separate column. Then the newspapers are grouped by the first three tokens and the newspaper_title is replaced by the shortest of newspaper title that shares the first three tokens. \n",
    "\n",
    "Question: Could it be that the different versions of the same newspaper have been distributed in different cities? \n",
    "\n",
    "- Perhaps the cities should not play an important role in the challegens. \n",
    "- Perhaps I have to write a more sophisticated code that combines all distribution places of all the versions of a single newspaper into a longer list and adds this list to the final paper_publication_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9199cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract first three tokens from a string\n",
    "# def extract_tokens(title):\n",
    "#     tokens = title.split()\n",
    "#     return ' '.join(tokens[:3])\n",
    "\n",
    "# # Apply the function to create a new column for the first three tokens\n",
    "# newspapers_1914_1945_df['first_three_tokens'] = newspapers_1914_1945_df['paper_title'].apply(extract_tokens)\n",
    "\n",
    "# # Group by the first three tokens and aggregate to get the shortest title\n",
    "# paper_publication_df = newspapers_1914_1945_df.groupby('first_three_tokens').agg(\n",
    "#     paper_title=('paper_title', lambda x: min(x, key=len)),\n",
    "#     publication_begin=('publication_date', 'min'),\n",
    "#     publication_end=('publication_date', 'max'),\n",
    "#     place_of_distribution=('place_of_distribution', 'first')\n",
    "# ).reset_index()\n",
    "\n",
    "# # Drop the temporary column\n",
    "# paper_publication_df.drop(columns='first_three_tokens', inplace=True)\n",
    "\n",
    "# paper_publication_df.to_pickle(\"./data_deutsches_zeitungsportal_1914_1945/paper_publication_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f9f7353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>publication_begin</th>\n",
       "      <th>publication_end</th>\n",
       "      <th>place_of_distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachener Anzeiger : politisches Tageblatt : be...</td>\n",
       "      <td>1914-01-01</td>\n",
       "      <td>1943-12-31</td>\n",
       "      <td>[Aachen, Regierungsbezirk Aachen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aachener Rundschau : politische und soziale Ta...</td>\n",
       "      <td>1916-01-04</td>\n",
       "      <td>1916-03-31</td>\n",
       "      <td>[Aachen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahauser Kreiszeitung : amtliches Kreisblatt fü...</td>\n",
       "      <td>1933-01-01</td>\n",
       "      <td>1933-03-31</td>\n",
       "      <td>[Ahaus, Stadtlohn, Vreden, Heek, Legden, Südlohn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akademische Mitteilungen : amtliches Mitteilun...</td>\n",
       "      <td>1922-05-31</td>\n",
       "      <td>1930-07-15</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alb-Bote : Rundschau von der Alb : Münsinger K...</td>\n",
       "      <td>1914-01-02</td>\n",
       "      <td>1945-04-21</td>\n",
       "      <td>[Münsingen (Baden-Württemberg)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Zurückverlangte Neuigkeiten</td>\n",
       "      <td>1914-01-31</td>\n",
       "      <td>1921-12-31</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Zweites Blatt der Tremonia. 1934-1934</td>\n",
       "      <td>1934-01-02</td>\n",
       "      <td>1934-03-30</td>\n",
       "      <td>[Castrop-Rauxel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Zwischen Grube und Scholle. 1932-1934</td>\n",
       "      <td>1932-07-07</td>\n",
       "      <td>1932-10-10</td>\n",
       "      <td>[Bergheim (Erft)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>Über die Grenzen : von Flüchtlingen für Flücht...</td>\n",
       "      <td>1944-11-30</td>\n",
       "      <td>1945-12-31</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Über die Verhandlungen der Sächsischen Volkska...</td>\n",
       "      <td>1919-02-26</td>\n",
       "      <td>1920-10-30</td>\n",
       "      <td>[Dresden]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_title publication_begin  \\\n",
       "0    Aachener Anzeiger : politisches Tageblatt : be...        1914-01-01   \n",
       "1    Aachener Rundschau : politische und soziale Ta...        1916-01-04   \n",
       "2    Ahauser Kreiszeitung : amtliches Kreisblatt fü...        1933-01-01   \n",
       "3    Akademische Mitteilungen : amtliches Mitteilun...        1922-05-31   \n",
       "4    Alb-Bote : Rundschau von der Alb : Münsinger K...        1914-01-02   \n",
       "..                                                 ...               ...   \n",
       "775                        Zurückverlangte Neuigkeiten        1914-01-31   \n",
       "776              Zweites Blatt der Tremonia. 1934-1934        1934-01-02   \n",
       "777              Zwischen Grube und Scholle. 1932-1934        1932-07-07   \n",
       "778  Über die Grenzen : von Flüchtlingen für Flücht...        1944-11-30   \n",
       "779  Über die Verhandlungen der Sächsischen Volkska...        1919-02-26   \n",
       "\n",
       "    publication_end                              place_of_distribution  \n",
       "0        1943-12-31                  [Aachen, Regierungsbezirk Aachen]  \n",
       "1        1916-03-31                                           [Aachen]  \n",
       "2        1933-03-31  [Ahaus, Stadtlohn, Vreden, Heek, Legden, Südlohn]  \n",
       "3        1930-07-15                                               None  \n",
       "4        1945-04-21                    [Münsingen (Baden-Württemberg)]  \n",
       "..              ...                                                ...  \n",
       "775      1921-12-31                                               None  \n",
       "776      1934-03-30                                   [Castrop-Rauxel]  \n",
       "777      1932-10-10                                  [Bergheim (Erft)]  \n",
       "778      1945-12-31                                               None  \n",
       "779      1920-10-30                                          [Dresden]  \n",
       "\n",
       "[780 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_publication_df= pd.read_pickle(\"./data_deutsches_zeitungsportal_1914_1945/paper_publication_df\")\n",
    "paper_publication_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd98d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732ee9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
